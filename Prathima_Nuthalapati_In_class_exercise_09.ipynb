{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Prathima_Nuthalapati_In_class_exercise_09.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pn0159/prathima_INFO5731_Fall2020/blob/master/Prathima_Nuthalapati_In_class_exercise_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Tp5rrMfxl1V"
      },
      "source": [
        "# **The ninth in-class-exercise (20 points in total, 11/11/2020)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXKDTSxuxl1e"
      },
      "source": [
        "The purpose of the exercise is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/INFO5731_FALL2020/blob/master/In_class_exercise/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVEdYHIkxl1g"
      },
      "source": [
        "#Importing necessary libraries\n",
        "\n",
        "import pandas as pd \n",
        "import re \n",
        "import nltk \n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem.porter import PorterStemmer \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuO4bcAQsXWV"
      },
      "source": [
        "#Loading the Train data and Test data\n",
        "\n",
        "my_data_train=pd.read_fwf(\"/content/sample_data/stsa-train.txt\", header=None)\n",
        "my_data_train= pd.DataFrame(my_data_train)\n",
        "my_data_test=pd.read_fwf(\"/content/sample_data/stsa-test.txt\", header=None)\n",
        "my_data_test= pd.DataFrame(my_data_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7C01IWLsXY7"
      },
      "source": [
        "#Now splitting the my_data_train in to training and validation data\n",
        "\n",
        "del my_data_train[2]\n",
        "my_data_train = my_data_train.rename(columns={0: \"Review\", 1: \"Text\"})\n",
        "del my_data_test[2]\n",
        "del my_data_test[3]\n",
        "my_data_test = my_data_test.rename(columns={0: \"Review\", 1: \"Text\"})\n",
        "x_train, x_validate, y_train, y_validate = sklearn.model_selection.train_test_split(my_data_train['Text'], my_data_train['Review'], train_size=0.8, test_size=0.2)\n",
        "x_train = x_train.to_numpy()\n",
        "y_train = y_train.to_numpy()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bqf6Rg6sXbl"
      },
      "source": [
        "# Defining K-fold(K=10)\n",
        "my_kf = KFold(n_splits=10)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0dXCKKnsXfD"
      },
      "source": [
        "# Analysis of Various Algorithms\n",
        "#MultinominalNB:\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', MultinomialNB())])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    MNB_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = MNB_algorithm.predict(x_validate)\n",
        "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUSV-BWOtuKQ",
        "outputId": "ab60d3c6-246a-4507-a4eb-be2885e3f788",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Evaluation of MultinominalNB:\n",
        "\n",
        "my_final = MNB_algorithm.predict(my_data_test['Text'])\n",
        "print('Accuracy of MultinomialNB :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('Recall of MultinomialNB :', (recall_score(my_data_test['Review'], my_final)*100))\n",
        "print('Precision of MultinomialNB :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('F1-score of MultinomialNB :', (f1_score(my_data_test['Review'], my_final, average='macro')*100))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of MultinomialNB : 79.8462383305876\n",
            "Recall of MultinomialNB : 85.47854785478548\n",
            "Precision of MultinomialNB : 79.8462383305876\n",
            "F1-score of MultinomialNB : 79.78527792002579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ClVYvMJuMYJ"
      },
      "source": [
        "# Analysis of Various Algorithms\n",
        "#SVM:\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', LinearSVC())])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    SVM_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = SVM_algorithm.predict(x_validate)\n",
        "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyKW3hI9uMbB",
        "outputId": "8f823c59-94af-455c-9e9f-cfb5d3914c5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Evaluation of SVM:\n",
        "my_final = SVM_algorithm.predict(my_data_test['Text'])\n",
        "print(' Accuracy of SVM :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('Recall of SVM :', (recall_score(my_data_test['Review'], my_final)*100))\n",
        "print(' Precision of SVM :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('F1-score of SVM :', (f1_score(my_data_test['Review'], my_final, average='macro')*100))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy of SVM : 78.19879187259747\n",
            "Recall of SVM : 80.41804180418042\n",
            " Precision of SVM : 78.19879187259747\n",
            "F1-score of SVM : 78.18929420379008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G46ewW6puMeA"
      },
      "source": [
        "# Analysis of Various Algorithms\n",
        "#KNN:\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', KNeighborsClassifier())])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    KNN_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = KNN_algorithm.predict(x_validate)\n",
        "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vviVLSHLuMg-",
        "outputId": "9079850f-6be7-4102-a9ab-bc58f1f61980",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Evaluation of KNN:\n",
        "my_final = KNN_algorithm.predict(my_data_test['Text'])\n",
        "print(' Accuracy of KNN :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('Recall of KNN :', (recall_score(my_data_test['Review'], my_final)*100))\n",
        "print(' Precision of KNN :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('F1-score of KNN :', (f1_score(my_data_test['Review'], my_final, average='macro')*100))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy of KNN : 72.48764415156508\n",
            "Recall of KNN : 76.12761276127613\n",
            " Precision of KNN : 72.48764415156508\n",
            "F1-score of KNN : 72.45361864402942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfMgHi8Ixrse"
      },
      "source": [
        "# Analysis of Various Algorithms\n",
        "#Decision Tree:\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', tree.DecisionTreeClassifier())])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    DT_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = DT_algorithm.predict(x_validate)\n",
        "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdvjaTTIyUeL",
        "outputId": "d6993177-c391-4959-f8fb-68be1ac69ccd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Evaluation of Decision Tree:\n",
        "my_final = DT_algorithm.predict(my_data_test['Text'])\n",
        "print(' Accuracy of Decision Tree :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('Recall of Decision Tree :', (recall_score(my_data_test['Review'], my_final)*100))\n",
        "print(' Precision of Decision Tree :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('F1-score of Decision Tree :', (f1_score(my_data_test['Review'], my_final, average='macro')*100))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy of Decision Tree : 59.14332784184514\n",
            "Recall of Decision Tree : 64.7964796479648\n",
            " Precision of Decision Tree : 59.14332784184514\n",
            "F1-score of Decision Tree : 59.01725431357839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-tT7YEYxrvv"
      },
      "source": [
        "# Analysis of Various Algorithms\n",
        "#Random Forest:\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', RandomForestClassifier(n_estimators=100))])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    RF_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = RF_algorithm.predict(x_validate)\n",
        "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1j1k7S1zBBw",
        "outputId": "3f214976-c331-469c-e3d5-7ca152a60753",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Evaluation of Random Forest:\n",
        "my_final = RF_algorithm.predict(my_data_test['Text'])\n",
        "print(' Accuracy of Random Forest :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('Recall of Random Forest :', (recall_score(my_data_test['Review'], my_final)*100))\n",
        "print(' Precision of Random Forest :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('F1-score of Random Forest :', (f1_score(my_data_test['Review'], my_final, average='macro')*100))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy of Random Forest : 71.82866556836903\n",
            "Recall of Random Forest : 75.9075907590759\n",
            " Precision of Random Forest : 71.82866556836903\n",
            "F1-score of Random Forest : 71.7845560832135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaviQYhuxr4D",
        "outputId": "bd23a1d0-6646-4793-c215-5a5d91190f03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Analysis of Various Algorithms\n",
        "#XGBoost:\n",
        "pln = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', GradientBoostingClassifier(n_estimators=20,verbose=2))])\n",
        "for train_index, test_index in my_kf.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "    \n",
        "    XGB_algorithm = pln.fit(x_train_k, y_train_k)\n",
        "pred_validate = XGB_algorithm.predict(x_validate)\n",
        "validation = {'Actual': y_validate, 'Predicted': pred_validate}\n",
        "validation_df = pd.DataFrame(validation, columns = ['Actual', 'Predicted'])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3757            0.64s\n",
            "         2           1.3682            0.60s\n",
            "         3           1.3616            0.55s\n",
            "         4           1.3556            0.51s\n",
            "         5           1.3500            0.47s\n",
            "         6           1.3451            0.44s\n",
            "         7           1.3404            0.41s\n",
            "         8           1.3358            0.37s\n",
            "         9           1.3314            0.34s\n",
            "        10           1.3271            0.31s\n",
            "        11           1.3232            0.28s\n",
            "        12           1.3193            0.25s\n",
            "        13           1.3157            0.21s\n",
            "        14           1.3127            0.18s\n",
            "        15           1.3091            0.15s\n",
            "        16           1.3055            0.12s\n",
            "        17           1.3020            0.09s\n",
            "        18           1.2988            0.06s\n",
            "        19           1.2954            0.03s\n",
            "        20           1.2925            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3758            0.63s\n",
            "         2           1.3687            0.58s\n",
            "         3           1.3626            0.55s\n",
            "         4           1.3568            0.51s\n",
            "         5           1.3514            0.47s\n",
            "         6           1.3463            0.45s\n",
            "         7           1.3418            0.42s\n",
            "         8           1.3372            0.39s\n",
            "         9           1.3329            0.35s\n",
            "        10           1.3289            0.32s\n",
            "        11           1.3248            0.28s\n",
            "        12           1.3217            0.25s\n",
            "        13           1.3179            0.22s\n",
            "        14           1.3143            0.19s\n",
            "        15           1.3113            0.16s\n",
            "        16           1.3081            0.12s\n",
            "        17           1.3046            0.09s\n",
            "        18           1.3009            0.06s\n",
            "        19           1.2979            0.03s\n",
            "        20           1.2953            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3751            0.61s\n",
            "         2           1.3674            0.56s\n",
            "         3           1.3608            0.54s\n",
            "         4           1.3550            0.51s\n",
            "         5           1.3497            0.47s\n",
            "         6           1.3448            0.44s\n",
            "         7           1.3401            0.42s\n",
            "         8           1.3355            0.38s\n",
            "         9           1.3313            0.35s\n",
            "        10           1.3267            0.32s\n",
            "        11           1.3229            0.28s\n",
            "        12           1.3190            0.25s\n",
            "        13           1.3157            0.22s\n",
            "        14           1.3125            0.19s\n",
            "        15           1.3091            0.16s\n",
            "        16           1.3056            0.13s\n",
            "        17           1.3024            0.09s\n",
            "        18           1.2993            0.06s\n",
            "        19           1.2963            0.03s\n",
            "        20           1.2931            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3763            0.58s\n",
            "         2           1.3690            0.54s\n",
            "         3           1.3626            0.50s\n",
            "         4           1.3570            0.47s\n",
            "         5           1.3520            0.44s\n",
            "         6           1.3473            0.41s\n",
            "         7           1.3430            0.39s\n",
            "         8           1.3383            0.36s\n",
            "         9           1.3341            0.33s\n",
            "        10           1.3300            0.30s\n",
            "        11           1.3264            0.27s\n",
            "        12           1.3227            0.24s\n",
            "        13           1.3194            0.21s\n",
            "        14           1.3157            0.18s\n",
            "        15           1.3128            0.15s\n",
            "        16           1.3098            0.12s\n",
            "        17           1.3068            0.09s\n",
            "        18           1.3036            0.06s\n",
            "        19           1.3004            0.03s\n",
            "        20           1.2979            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3755            0.60s\n",
            "         2           1.3675            0.57s\n",
            "         3           1.3609            0.53s\n",
            "         4           1.3553            0.50s\n",
            "         5           1.3497            0.46s\n",
            "         6           1.3450            0.43s\n",
            "         7           1.3401            0.41s\n",
            "         8           1.3357            0.37s\n",
            "         9           1.3316            0.34s\n",
            "        10           1.3279            0.31s\n",
            "        11           1.3240            0.28s\n",
            "        12           1.3201            0.24s\n",
            "        13           1.3164            0.21s\n",
            "        14           1.3130            0.18s\n",
            "        15           1.3102            0.16s\n",
            "        16           1.3071            0.12s\n",
            "        17           1.3043            0.09s\n",
            "        18           1.3006            0.06s\n",
            "        19           1.2980            0.03s\n",
            "        20           1.2952            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3757            0.59s\n",
            "         2           1.3679            0.55s\n",
            "         3           1.3613            0.52s\n",
            "         4           1.3552            0.48s\n",
            "         5           1.3501            0.45s\n",
            "         6           1.3452            0.42s\n",
            "         7           1.3404            0.40s\n",
            "         8           1.3364            0.37s\n",
            "         9           1.3323            0.35s\n",
            "        10           1.3277            0.31s\n",
            "        11           1.3234            0.28s\n",
            "        12           1.3199            0.25s\n",
            "        13           1.3167            0.22s\n",
            "        14           1.3133            0.19s\n",
            "        15           1.3100            0.15s\n",
            "        16           1.3066            0.12s\n",
            "        17           1.3040            0.09s\n",
            "        18           1.3008            0.06s\n",
            "        19           1.2972            0.03s\n",
            "        20           1.2936            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3768            0.58s\n",
            "         2           1.3697            0.54s\n",
            "         3           1.3630            0.52s\n",
            "         4           1.3572            0.49s\n",
            "         5           1.3520            0.46s\n",
            "         6           1.3471            0.44s\n",
            "         7           1.3423            0.41s\n",
            "         8           1.3381            0.38s\n",
            "         9           1.3337            0.35s\n",
            "        10           1.3294            0.31s\n",
            "        11           1.3255            0.28s\n",
            "        12           1.3223            0.25s\n",
            "        13           1.3192            0.22s\n",
            "        14           1.3158            0.19s\n",
            "        15           1.3124            0.16s\n",
            "        16           1.3093            0.12s\n",
            "        17           1.3060            0.09s\n",
            "        18           1.3031            0.06s\n",
            "        19           1.2997            0.03s\n",
            "        20           1.2971            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3758            0.62s\n",
            "         2           1.3681            0.58s\n",
            "         3           1.3612            0.55s\n",
            "         4           1.3549            0.50s\n",
            "         5           1.3497            0.47s\n",
            "         6           1.3442            0.43s\n",
            "         7           1.3396            0.40s\n",
            "         8           1.3350            0.37s\n",
            "         9           1.3307            0.34s\n",
            "        10           1.3265            0.31s\n",
            "        11           1.3226            0.28s\n",
            "        12           1.3190            0.24s\n",
            "        13           1.3149            0.21s\n",
            "        14           1.3113            0.18s\n",
            "        15           1.3085            0.15s\n",
            "        16           1.3050            0.12s\n",
            "        17           1.3012            0.09s\n",
            "        18           1.2981            0.06s\n",
            "        19           1.2945            0.03s\n",
            "        20           1.2917            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3759            0.59s\n",
            "         2           1.3684            0.55s\n",
            "         3           1.3620            0.55s\n",
            "         4           1.3559            0.51s\n",
            "         5           1.3509            0.47s\n",
            "         6           1.3465            0.43s\n",
            "         7           1.3422            0.40s\n",
            "         8           1.3376            0.37s\n",
            "         9           1.3331            0.34s\n",
            "        10           1.3294            0.31s\n",
            "        11           1.3255            0.28s\n",
            "        12           1.3222            0.25s\n",
            "        13           1.3188            0.21s\n",
            "        14           1.3152            0.19s\n",
            "        15           1.3119            0.15s\n",
            "        16           1.3091            0.12s\n",
            "        17           1.3065            0.09s\n",
            "        18           1.3034            0.06s\n",
            "        19           1.2999            0.03s\n",
            "        20           1.2974            0.00s\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3762            0.62s\n",
            "         2           1.3684            0.56s\n",
            "         3           1.3619            0.52s\n",
            "         4           1.3564            0.49s\n",
            "         5           1.3513            0.46s\n",
            "         6           1.3464            0.42s\n",
            "         7           1.3412            0.40s\n",
            "         8           1.3372            0.37s\n",
            "         9           1.3332            0.34s\n",
            "        10           1.3293            0.31s\n",
            "        11           1.3254            0.27s\n",
            "        12           1.3222            0.24s\n",
            "        13           1.3189            0.22s\n",
            "        14           1.3159            0.19s\n",
            "        15           1.3124            0.15s\n",
            "        16           1.3091            0.12s\n",
            "        17           1.3060            0.09s\n",
            "        18           1.3030            0.06s\n",
            "        19           1.2997            0.03s\n",
            "        20           1.2965            0.00s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv1F4eFVxsBa",
        "outputId": "a2be3557-7f99-4fd5-9113-2a4b0fe44940",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Evaluation of XG Boost::\n",
        "my_final = XGB_algorithm.predict(my_data_test['Text'])\n",
        "print(' Accuracy of XG Boost :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('Recall of XG Boost :', (recall_score(my_data_test['Review'], my_final)*100))\n",
        "print(' Precision of XG Boost :', (accuracy_score(my_data_test['Review'], my_final)*100))\n",
        "print('F1-score of XG Boost :', (f1_score(my_data_test['Review'], my_final, average='macro')*100))\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy of XG Boost : 59.527732015376166\n",
            "Recall of XG Boost : 88.33883388338833\n",
            " Precision of XG Boost : 59.527732015376166\n",
            "F1-score of XG Boost : 55.90432510381766\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}